{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15e7e703",
   "metadata": {},
   "source": [
    "#### The goal of this exploratory data analysis (EDA) is to understand customer preferences and restaurant performance in Bangalore using the Zomato dataset. Specifically, this analysis aims to:\n",
    "\n",
    "#### Explore the Relationship Between Ratings and Orders:\n",
    ">By examining the correlation between restaurant ratings and the number of orders, we aim to uncover how customer satisfaction (via ratings) impacts the popularity and demand for restaurants in Bangalore.\n",
    "\n",
    "#### Explore the preferences of people of Bangalore:\n",
    ">The type of food that is most preferred by people in different regions of the city.\n",
    "\n",
    "#### Perform Geospatial Analysis: \n",
    ">This analysis will focus on identifying the geographical distribution of different cuisines across Bangalore. We will investigate which areas have the highest concentration of specific cuisines.\n",
    "\n",
    "#### The findings will help provide insights into:\n",
    "\n",
    ">How customer ratings influence restaurant success. <br>\n",
    ">Popular food trends in Bangalore.<br>\n",
    ">The areas in Bangalore where specific types of cuisine are most in demand, potentially helping restaurants make data-driven decisions about location and menu offerings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41ea0e2",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d715573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "import folium\n",
    "from nltk.corpus import RegexpTokenizer\n",
    "from folium.plugins import HeatMap\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist, bigrams , trigrams\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4568cea7",
   "metadata": {},
   "source": [
    "#### Reading data from a sqlite file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcadb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "db =sqlite3.connect(r\"zomato_rawdata.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de734e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(\"SELECT * FROM Users\", db).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb40fd8",
   "metadata": {},
   "source": [
    "Creating a Pandas dateframe using a sql quaery from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73f31da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM Users\" , db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d129f1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984f97cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814e5a9a",
   "metadata": {},
   "source": [
    "#### Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44912a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d04803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of missing values in each column\n",
    "null_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "# Format the result as percentages with 2 decimal places\n",
    "null_percentage_formatted = null_percentage.map('{:.2f}%'.format)\n",
    "\n",
    "print(null_percentage_formatted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fc51ed",
   "metadata": {},
   "source": [
    "#### Since approximately 50% of the data would be lost by removing the missing values in the dish_liked column, we will retain this column for now.\n",
    "\n",
    "#### Next, let's examine the rate column, which has 15% missing values. Given that this is a key feature, it's important to address this carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6665c1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rate'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bac453",
   "metadata": {},
   "source": [
    "#### I identified that this column contains 'NEW' and '-' values. These should be replaced with zero or np.nan.\n",
    "\n",
    "#### I also noticed some entries like '3.8/5' instead of just '3.8'. We'll need to clean and standardize these values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff28977",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rate'].replace(('NEW' , '-') , np.nan , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4742c3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rate']=df['rate'].apply(lambda x: float(x.split('/')[0]) if type(x) == str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110f03a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.rate.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5f168d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd61d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rate'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9c7987",
   "metadata": {},
   "source": [
    " We aim to explore how many restaurants with ratings such as 0, 1, 1.2, 1.4, 1.6, and so on accept or do not accept online orders.\n",
    "\n",
    ">To address this, we'll create frequency tables to capture the distribution of ratings across restaurants that accept online orders and those that don't.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9f1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.crosstab(df['rate'] , df['online_order'])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1cc30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.plot(kind='bar', stacked=True, color=['#2D2D2D','#cb202d'], figsize=(10, 6))\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Ratings vs Nature of Orders', fontsize=16)\n",
    "plt.xlabel('Ratings', fontsize=12)\n",
    "plt.ylabel('No. of Orders', fontsize=12)\n",
    "\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Add a grid for better readability\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(title='Online Order?', loc='upper right', fontsize=10)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd200c26",
   "metadata": {},
   "source": [
    "We need to perform floating division of the DataFrame, or normalize the values in the x DataFrame across rows. To achieve this, we can use the x.div() function and set axis=0.\n",
    "\n",
    "The div() function is an in-built method in pandas designed specifically for DataFrame operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de8be78",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_df = x.div(x.sum(axis=1).astype(float) , axis=0)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f75a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_df.plot(kind='bar', stacked=True, color=['#2D2D2D','#cb202d'], figsize=(10, 6))\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Ratings vs Nature of Orders', fontsize=16)\n",
    "plt.xlabel('Ratings', fontsize=12)\n",
    "plt.ylabel('No. of Orders', fontsize=12)\n",
    "\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Add a grid for better readability\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(title='Online Order?', loc='upper right', fontsize=10)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5386e8d2",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "\n",
    ">For restaurants with good ratings (i.e., greater than 4), it appears that in most cases, those that accept online orders tend to receive a higher number of ratings compared to restaurants that do not offer online ordering.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e3adc3",
   "metadata": {},
   "source": [
    "### Data Cleaning to perform Text Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d18da4e",
   "metadata": {},
   "source": [
    "We are going to check the different kinds of restaurants we have here but first, we need to remove missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd77e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_data = df.dropna(subset=['rest_type']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f8662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_data['rest_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d3834f",
   "metadata": {},
   "source": [
    "Let's pick 'Quick Bites' type restaurants to make some inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6d4dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_bites_df = rest_data[rest_data['rest_type'].str.contains('Quick Bites')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a7c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_bites_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac1f121",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_bites_df.reviews_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad25031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_bites_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12442986",
   "metadata": {},
   "source": [
    "### Text Data Pre-processing Steps:\n",
    ">Convert Text to Lowercase: Transform all text data to lowercase for uniformity.<br>\n",
    ">Tokenization: Break down the text into individual tokens (words).<br>\n",
    ">Remove Stopwords: Eliminate common stopwords (e.g., \"and\", \"the\") from the data to focus on meaningful words.<br>\n",
    ">Store Data in a List: Store the processed data in a list to compute word frequency.<br>\n",
    ">Plot Word Frequencies: Perform Unigram, Bigram, and Trigram analysis to visualize word frequencies and patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387b8ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming all text data to lowercase \n",
    "quick_bites_df['reviews_list'] = quick_bites_df['reviews_list'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f94a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Creating a regular expression tokenizer that have only alphabets , ie remove all the special characters\n",
    "\n",
    "tokenizer = RegexpTokenizer(\"[a-zA-Z]+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a01724",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c1dd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_tokens = df['reviews_list'].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6f4656",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2ac799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing stopwords of English\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad2f787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding custom words to stopwords \n",
    "stop.extend(['rated' , \"n\" , \"nan\" , \"x\" , \"RATED\" , \"Rated\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e70ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove stopwords from \"reviews_tokens\" Series ..\n",
    "reviews_tokens_clean = reviews_tokens.apply(lambda x : [token for token in x if token not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eb9faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_tokens_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa9bf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the reviews into a 2d list\n",
    "rev = reviews_tokens_clean.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51720bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting words from each reviews to count them \n",
    "total_reviews=[]\n",
    "\n",
    "for review in rev:\n",
    "    for word in review:\n",
    "        total_reviews.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc77f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3337fc3",
   "metadata": {},
   "source": [
    "Unigram analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae382c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235d12b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in total_reviews:\n",
    "    fd[word] = fd[word] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d709671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining the top 20 most frequent words\n",
    "fd.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f42352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd.plot(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965e1823",
   "metadata": {},
   "source": [
    "#### Observations\n",
    ">The 20 most frequent words in customer reviews include \"place,\" \"food,\" \"good,\" \"chicken,\" \"taste,\" \"service,\" and \"ambience\"\n",
    "<br>\n",
    ">However, it's not entirely clear whether the food is actually good based solely on these words. Similarly, we need to examine the context of mentions regarding \"chicken.\"\n",
    "<br>\n",
    "To derive more meaningful insights, we should consider performing a Bi-gram analysis.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6948330",
   "metadata": {},
   "source": [
    "Bi-gram analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e26263",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_grams = bigrams(total_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6657a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_bigrams = FreqDist()\n",
    "\n",
    "for bigram in bi_grams:\n",
    "    fd_bigrams[bigram] = fd_bigrams[bigram] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cf5fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_bigrams.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c43dc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_bigrams.plot(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9c888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_bigrams.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91893c35",
   "metadata": {},
   "source": [
    "### Observations\n",
    "We have gained some new insights! The food items and preferences highlighted in the top 50 bigrams include:\n",
    "\n",
    "- Fried Rice\n",
    "- North Indian\n",
    "- Indian food\n",
    "- Non-Veg\n",
    "- Chicken Biryani\n",
    "- Main Course\n",
    "\n",
    "Factors contributing to the restaurant experience are:\n",
    "- Good Food\n",
    "- Goog Service\n",
    "- Pocket-Friendly\n",
    "- Good Ambience\n",
    "- Friendly behaviour of staffs\n",
    "- Home Delivery\n",
    "\n",
    "A key insight here is that the expense factor, which was overlooked in the individual word frequency counts, has been captured through the bigram frequency counts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7872e127",
   "metadata": {},
   "source": [
    "Tri-gram Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a40892",
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_grams = trigrams(total_reviews)\n",
    "fd_trigrams = FreqDist()\n",
    "\n",
    "for trigram in tri_grams:\n",
    "    fd_trigrams[trigram] = fd_trigrams[trigram] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01961803",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_trigrams.plot(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5323bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_trigrams.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865a9959",
   "metadata": {},
   "source": [
    "The specific food preferences highlighted include\n",
    "- North Indian food \n",
    "- Paneer Butter Masala\n",
    "- White Sauce Pasta\n",
    "- Vanilla Ice cream\n",
    "- Various chicken items. \n",
    "\n",
    "This indicates that Bangalore is home to many chicken lovers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3724484f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c794f2d",
   "metadata": {},
   "source": [
    "### Extract geographical coordinates from the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376a042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install geocoder\n",
    "#!pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aaf3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ba3b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b9c492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No. of unique locations\n",
    "len(df['location'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9add35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are adding the city, state and country to make precise analysis\n",
    "df['location'] = df['location'] + \" , Bangalore  , Karnataka , India \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168adb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192724a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14ee2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_copy.dropna(subset=['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d348de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = pd.DataFrame(df_copy['location'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429d7ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2659de29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naming the column\n",
    "locations.columns = ['Area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10abb155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985b14d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### assign timeout=None in order to get rid of timeout error..\n",
    "geolocator = Nominatim(user_agent=\"app\" , timeout=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8c50c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to assign co-ordinates into a list\n",
    "lat=[]\n",
    "lon=[]\n",
    "\n",
    "for location in locations['Area']:\n",
    "    location = geolocator.geocode(location)\n",
    "    if location is None:\n",
    "        lat.append(np.nan)\n",
    "        lon.append(np.nan)\n",
    "    else:\n",
    "        lat.append(location.latitude)\n",
    "        lon.append(location.longitude)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f354b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the latitude and longitude column in the locations dataset\n",
    "locations['latitude'] = lat\n",
    "locations['longitude'] = lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd1e85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b53187",
   "metadata": {},
   "outputs": [],
   "source": [
    "### lets find it out whether we have misssing values or not !\n",
    "locations.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a8242",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations[locations['latitude'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156a65d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding missing values from google search\n",
    "locations['latitude'][79] = 13.0163\n",
    "locations['longitude'][79] = 77.6785\n",
    "locations['latitude'][85] = 13.0068\n",
    "locations['longitude'][85] = 77.5813"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6cd5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cuisines'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f191a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['cuisines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f807f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cuisines.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3deaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's find it out what are those areas where we have most number of Momos restaurants ?\n",
    "#Because I love them\n",
    "\n",
    "momos = df[df['cuisines'].str.contains('Momo')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6d23ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "momos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c86b0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "momos_rest_count = momos['location'].value_counts().reset_index().rename(columns={'index':'name' , \"location\":\"Area\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771fc9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "momos_rest_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c4f16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_df = momos_rest_count.merge(locations , on='Area' , how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3716e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab46dacb",
   "metadata": {},
   "source": [
    "Adding Basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf7e106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install folium\n",
    "import folium\n",
    "basemap = folium.Map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a89ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af87c546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium.plugins import HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28ff924",
   "metadata": {},
   "outputs": [],
   "source": [
    "HeatMap(heatmap_df[['latitude', 'longitude' , \"count\"]]).add_to(basemap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3963ea73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basemap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f99324",
   "metadata": {},
   "source": [
    "#### Conclusions:\n",
    "- It is evident that restaurants are primarily concentrated in the central Bangalore area.\n",
    "- The density of restaurants decreases as we move away from the center.\n",
    "- This information can be valuable for potential restaurant entrepreneurs in identifying favorable locations for their ventures.\n",
    "- Itâ€™s important to note that heatmaps are most effective when we have latitude and longitude data or when indicating the significance or count of specific locations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43337393",
   "metadata": {},
   "source": [
    "#### Automating the task of generating basemap for different type of cuisnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b9115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heatmap(cuisine):\n",
    "    cuisine_df = df[df['cuisines'].str.contains(cuisine)]\n",
    "    \n",
    "    cuisine_rest_count = cuisine_df['location'].value_counts().reset_index().rename(columns={'index':'name' , \"location\":\"Area\"})\n",
    "    heatmap_df = cuisine_rest_count.merge(locations , on='Area' , how='left')\n",
    "    print(heatmap_df.head(4))\n",
    "    \n",
    "    basemap = folium.Map()\n",
    "    HeatMap(heatmap_df[['latitude', 'longitude' , \"count\"]]).add_to(basemap)\n",
    "    return basemap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ec2007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's find Bengali restaurants as I'm a Bengali and I'd love to find a place which serves bengali food\n",
    "get_heatmap('Bengali')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ac3459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for South Indian cuisines\n",
    "get_heatmap('South Indian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbd3dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for North Indian cuisines\n",
    "get_heatmap('North Indian')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a680da0",
   "metadata": {},
   "source": [
    "### Conclusion<br>\n",
    "\n",
    "- In this exploratory data analysis of the Zomato dataset, we uncovered valuable insights into restaurant dynamics in Bangalore. Our analysis revealed a strong correlation between restaurant ratings and the acceptance of online orders, indicating that restaurants with higher ratings tend to receive more online orders.\n",
    "\n",
    "- Furthermore, through unigram and bigram analyses, we identified prevalent food preferences among customers, with items such as Fried Rice, Paneer Butter Masala, Vanilla Icecream and Chicken Biryani frequently mentioned. This suggests that certain cuisines are particularly popular in the city, reflecting local tastes and dining habits.\n",
    "\n",
    "- Geospatial analysis highlighted the concentration of restaurants in central Bangalore, with a notable decrease in density as one moves outward. This information can be instrumental for potential restaurant entrepreneurs seeking to establish their businesses in high-traffic areas.\n",
    "\n",
    "- Overall, this EDA has provided a comprehensive understanding of customer preferences, restaurant performance, and geographical trends, laying a solid foundation for further research and business strategy development in the food and beverage sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2610266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
